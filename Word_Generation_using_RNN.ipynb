{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Generation_using_RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTZU4EdOELXLtWtFqrVj+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vicks-2019/NLP/blob/master/Word_Generation_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meK_nqdV5vKX"
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTOrbZFX56Ka"
      },
      "source": [
        "\n",
        "# source text\n",
        "data = \"\"\" Organizing a software company is a very specialized type of management skill\\n\n",
        "where experienced persons can turn the organizational problem into a unique benefit\\n\n",
        "There are two type of companies product based and service based company\\n\n",
        "A professional software company normally consists of at least dedicated team\\n \"\"\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugc6j5zk-z_f",
        "outputId": "26941ed6-31e1-496b-ad8e-fa9f0835a55e"
      },
      "source": [
        "# integer encode text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "encoded_data= tokenizer.texts_to_sequences([data])[0]\n",
        "encoded_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7,\n",
              " 1,\n",
              " 4,\n",
              " 2,\n",
              " 8,\n",
              " 1,\n",
              " 9,\n",
              " 10,\n",
              " 5,\n",
              " 3,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 1,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 5,\n",
              " 3,\n",
              " 27,\n",
              " 28,\n",
              " 6,\n",
              " 29,\n",
              " 30,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 31,\n",
              " 4,\n",
              " 2,\n",
              " 32,\n",
              " 33,\n",
              " 3,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb427c3Q-3pv",
        "outputId": "f93bba15-28c3-41da-8897-aa37a9b9587e"
      },
      "source": [
        "# determine the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1  # 0 is reserved for padding so that's why we added 1\n",
        "\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT8ZNz3t_Deq",
        "outputId": "94593209-b358-40e0-cba6-55f76841e314"
      },
      "source": [
        "# create word -> word sequences\n",
        "sequences = list()\n",
        "for i in range(1, len(encoded_data)):\n",
        "\tsequence = encoded_data[i-1:i+1]\n",
        "\tsequences.append(sequence)\n",
        "print('Total Sequences: %d' % len(sequences))\n",
        "# split into X and y elements"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kqTWTpC_KjA",
        "outputId": "f36d895c-b1c1-4426-bfb2-702bf001daa2"
      },
      "source": [
        "\n",
        "sequences\n",
        "#sequences[:5] # [input, output]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 1],\n",
              " [1, 4],\n",
              " [4, 2],\n",
              " [2, 8],\n",
              " [8, 1],\n",
              " [1, 9],\n",
              " [9, 10],\n",
              " [10, 5],\n",
              " [5, 3],\n",
              " [3, 11],\n",
              " [11, 12],\n",
              " [12, 13],\n",
              " [13, 14],\n",
              " [14, 15],\n",
              " [15, 16],\n",
              " [16, 17],\n",
              " [17, 18],\n",
              " [18, 19],\n",
              " [19, 20],\n",
              " [20, 21],\n",
              " [21, 1],\n",
              " [1, 22],\n",
              " [22, 23],\n",
              " [23, 24],\n",
              " [24, 25],\n",
              " [25, 26],\n",
              " [26, 5],\n",
              " [5, 3],\n",
              " [3, 27],\n",
              " [27, 28],\n",
              " [28, 6],\n",
              " [6, 29],\n",
              " [29, 30],\n",
              " [30, 6],\n",
              " [6, 2],\n",
              " [2, 1],\n",
              " [1, 31],\n",
              " [31, 4],\n",
              " [4, 2],\n",
              " [2, 32],\n",
              " [32, 33],\n",
              " [33, 3],\n",
              " [3, 34],\n",
              " [34, 35],\n",
              " [35, 36],\n",
              " [36, 37]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DKV0ONZ_TpT"
      },
      "source": [
        "\n",
        "sequences = array(sequences)\n",
        "X, y = sequences[:,0],sequences[:,1]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwDYTFHA_f7f",
        "outputId": "338e57e3-2c0d-45fd-be9d-1a8e7c1179c7"
      },
      "source": [
        "X[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 1, 4, 2, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-qsbPTw_jIU",
        "outputId": "803ee2ad-febb-4641-d2c6-b0703c1e9169"
      },
      "source": [
        "y[:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 4, 2, 8, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tOJ83he_lgy",
        "outputId": "b59d92f8-af5b-4c83-bf68-5e9d3f1b0144"
      },
      "source": [
        "# one hot encode outputs\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "# define model\n",
        "y[:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErKHIavV_ns4",
        "outputId": "4e6ede5f-ba2b-4db7-f07b-6036f449df38"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=1))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1, 10)             380       \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                12200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 38)                1938      \n",
            "=================================================================\n",
            "Total params: 14,518\n",
            "Trainable params: 14,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpxzCH9o_rMR"
      },
      "source": [
        "# compile network\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OAoeT-a_yjQ",
        "outputId": "313691c2-8e73-419f-f248-22356e03b14d"
      },
      "source": [
        "\n",
        "# fit network\n",
        "model.fit(X, y, epochs=80)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.6378 - accuracy: 0.0217\n",
            "Epoch 2/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6363 - accuracy: 0.0652\n",
            "Epoch 3/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6352 - accuracy: 0.0870\n",
            "Epoch 4/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6341 - accuracy: 0.0870\n",
            "Epoch 5/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6330 - accuracy: 0.0870\n",
            "Epoch 6/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6319 - accuracy: 0.0870\n",
            "Epoch 7/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6309 - accuracy: 0.0870\n",
            "Epoch 8/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6296 - accuracy: 0.0870\n",
            "Epoch 9/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6286 - accuracy: 0.0870\n",
            "Epoch 10/80\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.6273 - accuracy: 0.0870\n",
            "Epoch 11/80\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.6262 - accuracy: 0.0870\n",
            "Epoch 12/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6250 - accuracy: 0.0870\n",
            "Epoch 13/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6237 - accuracy: 0.0870\n",
            "Epoch 14/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6224 - accuracy: 0.0870\n",
            "Epoch 15/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6211 - accuracy: 0.0870\n",
            "Epoch 16/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6196 - accuracy: 0.0870\n",
            "Epoch 17/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6183 - accuracy: 0.0870\n",
            "Epoch 18/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6168 - accuracy: 0.0870\n",
            "Epoch 19/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6151 - accuracy: 0.0870\n",
            "Epoch 20/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6136 - accuracy: 0.0870\n",
            "Epoch 21/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6118 - accuracy: 0.0870\n",
            "Epoch 22/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6100 - accuracy: 0.0870\n",
            "Epoch 23/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.6083 - accuracy: 0.0870\n",
            "Epoch 24/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.6064 - accuracy: 0.0870\n",
            "Epoch 25/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.6043 - accuracy: 0.0870\n",
            "Epoch 26/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6021 - accuracy: 0.0870\n",
            "Epoch 27/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6000 - accuracy: 0.0870\n",
            "Epoch 28/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5976 - accuracy: 0.0870\n",
            "Epoch 29/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5953 - accuracy: 0.0870\n",
            "Epoch 30/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5927 - accuracy: 0.0870\n",
            "Epoch 31/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5901 - accuracy: 0.0870\n",
            "Epoch 32/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5873 - accuracy: 0.0870\n",
            "Epoch 33/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5844 - accuracy: 0.0870\n",
            "Epoch 34/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5813 - accuracy: 0.0870\n",
            "Epoch 35/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5780 - accuracy: 0.0870\n",
            "Epoch 36/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5748 - accuracy: 0.0870\n",
            "Epoch 37/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5710 - accuracy: 0.0870\n",
            "Epoch 38/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5675 - accuracy: 0.0870\n",
            "Epoch 39/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5631 - accuracy: 0.0870\n",
            "Epoch 40/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5594 - accuracy: 0.0870\n",
            "Epoch 41/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5547 - accuracy: 0.0870\n",
            "Epoch 42/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5501 - accuracy: 0.0870\n",
            "Epoch 43/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5452 - accuracy: 0.0870\n",
            "Epoch 44/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5399 - accuracy: 0.0870\n",
            "Epoch 45/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5348 - accuracy: 0.0870\n",
            "Epoch 46/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5289 - accuracy: 0.0870\n",
            "Epoch 47/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5231 - accuracy: 0.0870\n",
            "Epoch 48/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5168 - accuracy: 0.0870\n",
            "Epoch 49/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5100 - accuracy: 0.0870\n",
            "Epoch 50/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5038 - accuracy: 0.0870\n",
            "Epoch 51/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4960 - accuracy: 0.0870\n",
            "Epoch 52/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4888 - accuracy: 0.0870\n",
            "Epoch 53/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4808 - accuracy: 0.0870\n",
            "Epoch 54/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4728 - accuracy: 0.0870\n",
            "Epoch 55/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.4647 - accuracy: 0.0870\n",
            "Epoch 56/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4555 - accuracy: 0.0870\n",
            "Epoch 57/80\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4462 - accuracy: 0.0870\n",
            "Epoch 58/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4367 - accuracy: 0.0870\n",
            "Epoch 59/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4262 - accuracy: 0.0870\n",
            "Epoch 60/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.4163 - accuracy: 0.0870\n",
            "Epoch 61/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.4053 - accuracy: 0.0870\n",
            "Epoch 62/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3936 - accuracy: 0.1087\n",
            "Epoch 63/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3817 - accuracy: 0.1087\n",
            "Epoch 64/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3698 - accuracy: 0.1087\n",
            "Epoch 65/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3568 - accuracy: 0.1304\n",
            "Epoch 66/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3445 - accuracy: 0.1304\n",
            "Epoch 67/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3295 - accuracy: 0.1304\n",
            "Epoch 68/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3168 - accuracy: 0.1304\n",
            "Epoch 69/80\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3017 - accuracy: 0.1304\n",
            "Epoch 70/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2871 - accuracy: 0.1304\n",
            "Epoch 71/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2713 - accuracy: 0.1304\n",
            "Epoch 72/80\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2555 - accuracy: 0.1304\n",
            "Epoch 73/80\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.2396 - accuracy: 0.1304\n",
            "Epoch 74/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2225 - accuracy: 0.1304\n",
            "Epoch 75/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2066 - accuracy: 0.1304\n",
            "Epoch 76/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.1887 - accuracy: 0.1304\n",
            "Epoch 77/80\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.1714 - accuracy: 0.1522\n",
            "Epoch 78/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.1525 - accuracy: 0.1522\n",
            "Epoch 79/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.1352 - accuracy: 0.1957\n",
            "Epoch 80/80\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.1163 - accuracy: 0.1957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb6521ac1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFg1dwT1AKWr"
      },
      "source": [
        "# generate a sequence from the model\n",
        "def generate_seq(model, tokenizer, enter_text, n_pred):  \n",
        "\tin_text, result = enter_text, enter_text  # \n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_pred):\n",
        "        \n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\tencoded = array(encoded)\n",
        "        \n",
        "\t\t# predict a word in the vocabulary\n",
        "\t\tyhat = model.predict_classes(encoded)\n",
        "        \n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text, result = out_word, result + ' ' + out_word\n",
        "\treturn result"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjD6jqHlCEfO",
        "outputId": "edba1e28-965b-4087-ebb1-1cc44e9920e4"
      },
      "source": [
        "\n",
        "# evaluate\n",
        "print(generate_seq(model, tokenizer, 'software', 6))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "software a a a a a a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2bKVSCzCNF4",
        "outputId": "9b2cab8b-6487-47a5-b8e7-b5aa80a67910"
      },
      "source": [
        "# evaluate\n",
        "print(generate_seq(model, tokenizer, 'product', 3))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "product based a a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgB0IuuSCbeh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}